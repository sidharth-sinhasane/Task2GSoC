Installed Ollama and ran CodeLlama locally.

Built a Django app with a /LLMapp/generate endpoint on localhost:8000, accepting POST requests and returning model responses.

Tested successfully using Postman with a good prompt.
